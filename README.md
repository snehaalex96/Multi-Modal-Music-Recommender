# Multi-Modal-Music-Recommender
A Multi-Modal Music Recommendation System using audio, lyrics, and user interactions

# ðŸŽµ Multi-Modal Music Recommender

## ðŸ“Œ Project Overview
This project is a **Multi-Modal Music Recommendation System** that recommends songs based on:
- **Audio Features** ðŸŽ¶ (Extracted from GTZAN, Spotify)
- **Lyrics Analysis** ðŸ“œ (Musixmatch dataset)
- **Metadata & Genre Tags** ðŸŽ¼ (Tagtraum, Last.fm)
- **User Behavior** ðŸ‘¥ (Collaborative Filtering from Deezer Ego Nets)

## ðŸš€ Features
- **Content-Based Recommendations** (Audio, Lyrics, Metadata)
- **Collaborative Filtering** (User-based, Item-based)
- **Hybrid Model** (Combining multiple techniques)
- **Graph-Based Recommendations** (Neo4j)
- **Deployable API & UI (FastAPI + Streamlit)**


## ðŸ”§ Technologies Used
- **Python** (Pandas, NumPy, Scikit-learn)
- **Deep Learning** (PyTorch, Hugging Face)
- **FastAPI** (Backend API)
- **Streamlit** (Frontend UI)
- **Neo4j** (Graph-Based Recommendations)
- **Hugging Face Transformers** (NLP)
- **Librosa & TorchAudio** (Audio Processing)

## ðŸ“œ Setup & Installation
```bash
git clone https://github.com/YOUR_USERNAME/Multi-Modal-Music-Recommender.git
cd Multi-Modal-Music-Recommender
pip install -r requirements.txt


